{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove files and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify your folder path\n",
    "folder_paths = ['output/feature_image','output/feature_importance','output/model','output/prediction' ]\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "    # Loop through all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Remove only files (not subfolders)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "            print(f\"Removed file: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the shapefile\n",
    "# aoi_path = '../../study_area/palisades_aoi.shp'\n",
    "# aoi_gdf = gpd.read_file(aoi_path)\n",
    "\n",
    "# # Extract the bounding box (minx, miny, maxx, maxy)\n",
    "# bbox = aoi_gdf.total_bounds  # This gives the bounding box as a list [minx, miny, maxx, maxy]\n",
    "\n",
    "# print(\"Bounding Box:\", bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palisades\n",
    "minx, miny, maxx, maxy=337276.20835215, 3762751.49928493,  370706.59898943, 3781200.70468214\n",
    "# prefix=\"palisades\"\n",
    "# sample_data_path= \"../../sample_collection/palisades_random_sample.shp\"\n",
    "# clip_sample_output_path='sample/palisades_random_sample.shp'\n",
    "\n",
    "\n",
    "# # # eaton\n",
    "# minx, miny, maxx, maxy=390284.9643946937, 3778493.0553008374, 407654.9643946937, 3791083.0553008374\n",
    "# ## Eaton\n",
    "# prefix=\"eaton\"\n",
    "# sample_data_path= \"../../sample_collection/eaton_random_sample.shp\"\n",
    "# clip_sample_output_path='sample/eaton_random_sample.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_gdf = gpd.read_file(sample_data_path)\n",
    "\n",
    "# Define the bounding box (minx, miny, maxx, maxy)\n",
    "bbox = (minx, miny, maxx, maxy)  # Replace with actual bounds\n",
    "\n",
    "# Create a polygon from the bounding box\n",
    "bbox_polygon = box(*bbox)\n",
    "\n",
    "# Convert the bounding box to a GeoDataFrame\n",
    "bbox_gdf = gpd.GeoDataFrame({'geometry': [bbox_polygon]}, crs=sample_gdf.crs)\n",
    "\n",
    "# Clip the original GeoDataFrame with the bounding box\n",
    "clipped_gdf = gpd.overlay(sample_gdf, bbox_gdf, how='intersection')\n",
    "\n",
    "# Count the total number of rows (data points)\n",
    "total_rows = clipped_gdf.shape[0]\n",
    "class_column_name='class'\n",
    "\n",
    "# Count the number of unique classes (assuming the class column is named 'class')\n",
    "unique_classes = clipped_gdf[class_column_name].nunique()\n",
    "\n",
    "# Alternatively, to get a count of each unique class\n",
    "class_counts = clipped_gdf[class_column_name].value_counts()\n",
    "\n",
    "samples_per_class = clipped_gdf[clipped_gdf[class_column_name] == 1].shape[0]\n",
    "print(samples_per_class)\n",
    "# Function to sample a specified number of data points from each class\n",
    "clipped_gdf = clipped_gdf.groupby('class').apply(lambda x: x.sample(n=samples_per_class, random_state=42))\n",
    "\n",
    "# Reset index after applying the groupby operation\n",
    "clipped_gdf = clipped_gdf.reset_index(drop=True)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Total number of rows: {total_rows}\")\n",
    "print(f\"Number of unique classes: {unique_classes}\")\n",
    "print(f\"Class distribution:\\n{class_counts}\")\n",
    "\n",
    "# Save the clipped data to a new shapefile\n",
    "clipped_gdf.to_file(clip_sample_output_path)\n",
    "\n",
    "# Optional: Display the result\n",
    "clipped_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# input_sar_image_path  = \"../../Asc_SAR_Data_Processing/10_projection/subset_Asc_spksigma_TC_32611.tif\"\n",
    "# input_sar_image_path  = \"intermediate/sar_asc_avg.tif\"\n",
    "input_sar_image_path  = \"../../Desc_SAR_Data_Processing/11_ordered/subset_S1A_Desc_partial_Cal_Stack_Spk_TC_32611_ordered.tif\"\n",
    "\n",
    "\n",
    "# glcm_raster_path=\"input/dGLCM.tif\"\n",
    "# glcm_pca_raster_path=\"input/dGLCM_pca.tif\"\n",
    "# thermal_image_path=\"../../ThermalData/03_diff/dTRAD.tif\"\n",
    "# dnbr_image_path=\"../../S2_Data_Processing/Indices/04_CLIP/dNBR_bilinear_10_clip.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images_dict={\n",
    "            f\"palisades_dnbr_label_clip\":\"gt/palisades_dnbr_label.tif\",\n",
    "\n",
    "            # f\"{prefix}_s1_desc_ready\":input_sar_image_path,\n",
    "            # f\"{prefix}_s1_avg_ready\":input_sar_image_path,\n",
    "\n",
    "            #  f\"{prefix}_glcm_ready\":glcm_raster_path,\n",
    "            #  f\"{prefix}_glcm_pca_ready\":glcm_pca_raster_path,\n",
    "\n",
    "            #  f\"{prefix}_thermal_ready\":thermal_image_path,\n",
    "            # f\"{prefix}_dnbr_ready\":dnbr_image_path,\n",
    "             }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save in order: VH_PRE, VV_PRE, VH_POST, VV_POST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # save in order: VH_PRE, VV_PRE, VH_POST, VV_POST\n",
    "# input_sar_image_path=\"../../Desc_SAR_Data_Processing/10_projection/subset_S1A_Desc_partial_Cal_Stack_Spk_TC_32611.tif\"\n",
    "# output_ordered_image_path=\"../../Desc_SAR_Data_Processing/11_ordered/subset_S1A_Desc_partial_Cal_Stack_Spk_TC_32611_ordered.tif\"\n",
    "# with rasterio.open(input_sar_image_path) as dataset:\n",
    "#     vh_post_band=dataset.read(1)\n",
    "#     vv_post_band=dataset.read(2)\n",
    "#     vh_pre_band=dataset.read(3)\n",
    "#     vv_pre_band=dataset.read(4)\n",
    "#     meta=dataset.meta.copy()\n",
    "\n",
    "# # Write the clipped data to a new file\n",
    "# with rasterio.open(output_ordered_image_path, 'w', **meta) as dest:\n",
    "#     dest.write(vh_pre_band, 1)  \n",
    "#     dest.write(vv_pre_band, 2)  \n",
    "#     dest.write(vh_post_band, 3)  \n",
    "#     dest.write(vv_post_band, 4)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_key in list(images_dict.keys()):\n",
    "    print(image_key)\n",
    "\n",
    "    with rasterio.open(images_dict[image_key]) as dataset:\n",
    "        # Print the properties\n",
    "        print(f\"CRS: {dataset.crs}\")\n",
    "        print(f\"Width: {dataset.width}\")\n",
    "        print(f\"Height: {dataset.height}\")\n",
    "        print(f\"Extent: {dataset.bounds}\")\n",
    "        print(f\"Resolution: { dataset.res}\")\n",
    "        print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clipping data by extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_extent = (minx, miny, maxx, maxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_key in list(images_dict.keys()):\n",
    "\n",
    "    # print(image_key.endswith(\"s1_ready\"))\n",
    "    # Open the raster dataset\n",
    "    with rasterio.open(images_dict[image_key]) as dataset:\n",
    "\n",
    "        # Get the window for the specified extent\n",
    "        window = from_bounds(*clip_extent, dataset.transform)\n",
    "        # Read the data in that window\n",
    "        # clipped_data = dataset.read(1, window=window)  # Read the first band in the window\n",
    "        \n",
    "        # Get the new transform for the clipped data\n",
    "        clipped_transform = dataset.window_transform(window)\n",
    "        clipped_data = dataset.read(1, window=window)\n",
    "        # Define the metadata for the clipped raster\n",
    "        clipped_meta = dataset.meta.copy()\n",
    "        \n",
    "\n",
    "        # if image_key.endswith(\"s1_ready\"):\n",
    "        #     count=4\n",
    "        #     clipped_meta.update({\n",
    "        #     'height': clipped_data.shape[0],\n",
    "        #     'width': clipped_data.shape[1],\n",
    "        #     'transform': clipped_transform,\n",
    "        #     'count':4\n",
    "        # })\n",
    "        # else:\n",
    "        count=dataset.count\n",
    "        clipped_meta.update({\n",
    "        'height': clipped_data.shape[0],\n",
    "        'width': clipped_data.shape[1],\n",
    "        'transform': clipped_transform\n",
    "        })\n",
    "\n",
    "        # bands = dataset.read()\n",
    "        \n",
    "        # Write the clipped data to a new file\n",
    "        with rasterio.open(f'input/{image_key}.tif', 'w', **clipped_meta) as dest:\n",
    "            # if image_key.endswith(\"s1_ready\"):\n",
    "            #     vh_pre = dataset.read(3, window=window)\n",
    "            #     vv_pre = dataset.read(4, window=window)\n",
    "            #     vh_post= dataset.read(5, window=window)\n",
    "            #     vv_post= dataset.read(6, window=window)\n",
    "\n",
    "\n",
    "                \n",
    "            #     dest.write(vh_pre, 1)\n",
    "            #     dest.write(vv_pre, 2)\n",
    "            #     dest.write(vh_post, 3)\n",
    "            #     dest.write(vv_post, 4)\n",
    "            # else:\n",
    "            for i in range(count):\n",
    "                clipped_data = dataset.read(i+1, window=window)\n",
    "                dest.write(clipped_data, i+1)  # Write the first band\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "# Read the dNBR TIFF image using rasterio\n",
    "file_path = 'input/palisades_dnbr_ready.tif'  # Update with your dNBR image file path\n",
    "output_file_path = 'gt/palisades_label_0_17.tif'\n",
    "\n",
    "with rasterio.open(file_path) as src:\n",
    "    dNBR_data = src.read(1)  # Read the first band (assuming it's a single-band image)\n",
    "    print(np.min(dNBR_data),\"min\")\n",
    "# dNBR_data = np.nan_to_num(dNBR_data, nan=0, posinf=0, neginf=0)\n",
    "dNBR_data[dNBR_data == -3.4028235e+38] = np.nan  # Replace with NaN for better handling\n",
    "\n",
    "# Optionally, you can replace NaN values with 0 if you want\n",
    "dNBR_data = np.nan_to_num(dNBR_data, nan=0)\n",
    "# Flatten the data to 1D array for histogram calculation\n",
    "dNBR_flat = dNBR_data.flatten()\n",
    "\n",
    "# Plot histogram of dNBR values\n",
    "plt.hist(dNBR_flat, bins=50, range=(dNBR_flat.min(), dNBR_flat.max()), alpha=0.75, color='blue')\n",
    "plt.title(\"Histogram of dNBR Values\")\n",
    "plt.xlabel(\"dNBR values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Apply Otsu's thresholding method to find the optimal threshold\n",
    "threshold = threshold_otsu(dNBR_data)\n",
    "print(f\"Optimal threshold based on Otsu's method: {threshold}\")\n",
    "\n",
    "# Classify the dNBR image using the threshold (Burnt vs Non-burnt)\n",
    "classified_image = dNBR_data > threshold\n",
    "\n",
    "# Plot the classified image\n",
    "plt.imshow(classified_image, cmap='gray')\n",
    "plt.title(\"Classified Burnt Area (Burnt = White, Non-Burnt = Black)\")\n",
    "plt.colorbar(label=\"Class (0 = Non-Burnt, 1 = Burnt)\")\n",
    "plt.show()\n",
    "\n",
    "# Optionally, you can save the classified image as a new TIFF file\n",
    "with rasterio.open(output_file_path, 'w', driver='GTiff', height=dNBR_data.shape[0], width=dNBR_data.shape[1],\n",
    "                   count=1, dtype=dNBR_data.dtype, crs=src.crs, transform=src.transform) as dst:\n",
    "    dst.write(classified_image.astype(np.uint8), 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fire_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
