{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove files and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Specify your folder path\n",
    "# folder_paths = ['input/','sample/','output/correlation','output/feature_image','output/feature_importance','output/model','output/prediction' ,'output/sample_feature' ]\n",
    "\n",
    "# for folder_path in folder_paths:\n",
    "#     # Loop through all files in the folder\n",
    "#     for filename in os.listdir(folder_path):\n",
    "#         file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "#         # Remove only files (not subfolders)\n",
    "#         if os.path.isfile(file_path):\n",
    "#             os.remove(file_path)\n",
    "#             print(f\"Removed file: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the shapefile\n",
    "# aoi_path = '../../study_area/palisades_aoi.shp'\n",
    "# aoi_gdf = gpd.read_file(aoi_path)\n",
    "\n",
    "# # Extract the bounding box (minx, miny, maxx, maxy)\n",
    "# bbox = aoi_gdf.total_bounds  # This gives the bounding box as a list [minx, miny, maxx, maxy]\n",
    "\n",
    "# print(\"Bounding Box:\", bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palisades\n",
    "# minx, miny, maxx, maxy=337276.20835215, 3762751.49928493,  370706.59898943, 3781200.70468214\n",
    "# prefix=\"palisades\"\n",
    "# sample_data_path= \"../../sample_collection/palisades_random_sample.shp\"\n",
    "# clip_sample_output_path='sample/palisades_random_sample.shp'\n",
    "\n",
    "\n",
    "# # # eaton\n",
    "minx, miny, maxx, maxy=390284.9643946937, 3778493.0553008374, 407654.9643946937, 3791083.0553008374\n",
    "## Eaton\n",
    "prefix=\"eaton\"\n",
    "sample_data_path= \"../../sample_collection/eaton_random_sample.shp\"\n",
    "clip_sample_output_path='sample/eaton_random_sample.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_gdf = gpd.read_file(sample_data_path)\n",
    "\n",
    "# Define the bounding box (minx, miny, maxx, maxy)\n",
    "bbox = (minx, miny, maxx, maxy)  # Replace with actual bounds\n",
    "\n",
    "# Create a polygon from the bounding box\n",
    "bbox_polygon = box(*bbox)\n",
    "\n",
    "# Convert the bounding box to a GeoDataFrame\n",
    "bbox_gdf = gpd.GeoDataFrame({'geometry': [bbox_polygon]}, crs=sample_gdf.crs)\n",
    "\n",
    "# Clip the original GeoDataFrame with the bounding box\n",
    "clipped_gdf = gpd.overlay(sample_gdf, bbox_gdf, how='intersection')\n",
    "\n",
    "# Count the total number of rows (data points)\n",
    "total_rows = clipped_gdf.shape[0]\n",
    "class_column_name='class'\n",
    "\n",
    "# Count the number of unique classes (assuming the class column is named 'class')\n",
    "unique_classes = clipped_gdf[class_column_name].nunique()\n",
    "\n",
    "# Alternatively, to get a count of each unique class\n",
    "class_counts = clipped_gdf[class_column_name].value_counts()\n",
    "\n",
    "samples_per_class = clipped_gdf[clipped_gdf[class_column_name] == 1].shape[0]\n",
    "print(samples_per_class)\n",
    "# Function to sample a specified number of data points from each class\n",
    "clipped_gdf = clipped_gdf.groupby('class').apply(lambda x: x.sample(n=samples_per_class, random_state=42))\n",
    "\n",
    "# Reset index after applying the groupby operation\n",
    "clipped_gdf = clipped_gdf.reset_index(drop=True)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Total number of rows: {total_rows}\")\n",
    "print(f\"Number of unique classes: {unique_classes}\")\n",
    "print(f\"Class distribution:\\n{class_counts}\")\n",
    "\n",
    "# Save the clipped data to a new shapefile\n",
    "clipped_gdf.to_file(clip_sample_output_path)\n",
    "\n",
    "# Optional: Display the result\n",
    "clipped_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# input_sar_image_path  = \"../../Asc_SAR_Data_Processing/10_projection/subset_Asc_spksigma_TC_32611.tif\"\n",
    "# input_sar_image_path  = \"intermediate/sar_asc_avg.tif\"\n",
    "input_sar_image_path  = \"../../Desc_SAR_Data_Processing/11_ordered/subset_S1A_Desc_partial_Cal_Stack_Spk_TC_32611_ordered.tif\"\n",
    "\n",
    "\n",
    "# glcm_raster_path=\"input/dGLCM.tif\"\n",
    "# glcm_pca_raster_path=\"input/dGLCM_pca.tif\"\n",
    "# thermal_image_path=\"../../ThermalData/03_diff/dTRAD.tif\"\n",
    "# dnbr_image_path=\"../../S2_Data_Processing/Indices/04_CLIP/dNBR_bilinear_10_clip.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images_dict={\n",
    "            f\"{prefix}_s1_desc_ready\":input_sar_image_path,\n",
    "            # f\"{prefix}_s1_avg_ready\":input_sar_image_path,\n",
    "\n",
    "            #  f\"{prefix}_glcm_ready\":glcm_raster_path,\n",
    "            #  f\"{prefix}_glcm_pca_ready\":glcm_pca_raster_path,\n",
    "\n",
    "            #  f\"{prefix}_thermal_ready\":thermal_image_path,\n",
    "            # f\"{prefix}_dnbr_ready\":dnbr_image_path,\n",
    "             }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save in order: VH_PRE, VV_PRE, VH_POST, VV_POST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # save in order: VH_PRE, VV_PRE, VH_POST, VV_POST\n",
    "# input_sar_image_path=\"../../Desc_SAR_Data_Processing/10_projection/subset_S1A_Desc_partial_Cal_Stack_Spk_TC_32611.tif\"\n",
    "# output_ordered_image_path=\"../../Desc_SAR_Data_Processing/11_ordered/subset_S1A_Desc_partial_Cal_Stack_Spk_TC_32611_ordered.tif\"\n",
    "# with rasterio.open(input_sar_image_path) as dataset:\n",
    "#     vh_post_band=dataset.read(1)\n",
    "#     vv_post_band=dataset.read(2)\n",
    "#     vh_pre_band=dataset.read(3)\n",
    "#     vv_pre_band=dataset.read(4)\n",
    "#     meta=dataset.meta.copy()\n",
    "\n",
    "# # Write the clipped data to a new file\n",
    "# with rasterio.open(output_ordered_image_path, 'w', **meta) as dest:\n",
    "#     dest.write(vh_pre_band, 1)  \n",
    "#     dest.write(vv_pre_band, 2)  \n",
    "#     dest.write(vh_post_band, 3)  \n",
    "#     dest.write(vv_post_band, 4)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_key in list(images_dict.keys()):\n",
    "    print(image_key)\n",
    "\n",
    "    with rasterio.open(images_dict[image_key]) as dataset:\n",
    "        # Print the properties\n",
    "        print(f\"CRS: {dataset.crs}\")\n",
    "        print(f\"Width: {dataset.width}\")\n",
    "        print(f\"Height: {dataset.height}\")\n",
    "        print(f\"Extent: {dataset.bounds}\")\n",
    "        print(f\"Resolution: { dataset.res}\")\n",
    "        print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clipping data by extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_extent = (minx, miny, maxx, maxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_key in list(images_dict.keys()):\n",
    "\n",
    "    # print(image_key.endswith(\"s1_ready\"))\n",
    "    # Open the raster dataset\n",
    "    with rasterio.open(images_dict[image_key]) as dataset:\n",
    "\n",
    "        # Get the window for the specified extent\n",
    "        window = from_bounds(*clip_extent, dataset.transform)\n",
    "        # Read the data in that window\n",
    "        # clipped_data = dataset.read(1, window=window)  # Read the first band in the window\n",
    "        \n",
    "        # Get the new transform for the clipped data\n",
    "        clipped_transform = dataset.window_transform(window)\n",
    "        clipped_data = dataset.read(1, window=window)\n",
    "        # Define the metadata for the clipped raster\n",
    "        clipped_meta = dataset.meta.copy()\n",
    "        \n",
    "\n",
    "        # if image_key.endswith(\"s1_ready\"):\n",
    "        #     count=4\n",
    "        #     clipped_meta.update({\n",
    "        #     'height': clipped_data.shape[0],\n",
    "        #     'width': clipped_data.shape[1],\n",
    "        #     'transform': clipped_transform,\n",
    "        #     'count':4\n",
    "        # })\n",
    "        # else:\n",
    "        count=dataset.count\n",
    "        clipped_meta.update({\n",
    "        'height': clipped_data.shape[0],\n",
    "        'width': clipped_data.shape[1],\n",
    "        'transform': clipped_transform\n",
    "        })\n",
    "\n",
    "        # bands = dataset.read()\n",
    "        \n",
    "        # Write the clipped data to a new file\n",
    "        with rasterio.open(f'input/{image_key}.tif', 'w', **clipped_meta) as dest:\n",
    "            # if image_key.endswith(\"s1_ready\"):\n",
    "            #     vh_pre = dataset.read(3, window=window)\n",
    "            #     vv_pre = dataset.read(4, window=window)\n",
    "            #     vh_post= dataset.read(5, window=window)\n",
    "            #     vv_post= dataset.read(6, window=window)\n",
    "\n",
    "\n",
    "                \n",
    "            #     dest.write(vh_pre, 1)\n",
    "            #     dest.write(vv_pre, 2)\n",
    "            #     dest.write(vh_post, 3)\n",
    "            #     dest.write(vv_post, 4)\n",
    "            # else:\n",
    "            for i in range(count):\n",
    "                clipped_data = dataset.read(i+1, window=window)\n",
    "                dest.write(clipped_data, i+1)  # Write the first band\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fire_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
