{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# !pwd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "dir_path = Path(r\"/Users/rabinatwayana/Rabina/CDE II/Wildfire Project/SAR-Burnt-Area-Mapping/\")\n",
    "\n",
    "if dir_path.exists():\n",
    "    os.chdir(dir_path)\n",
    "else:\n",
    "    print(\"Directory does not exist! Please check the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "from rasterio.plot import show\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_sample_path=\"MachineLearning/sample/eaton_random_sample.shp\"\n",
    "\n",
    "path_1=\"MachineLearning/output/prediction/1_palisadesRF_eaton_sar_asc.tif\"\n",
    "path_2=\"MachineLearning/output/prediction/2_palisadesRF_eaton_sar_asc_glcm.tif\"\n",
    "path_3=\"MachineLearning/output/prediction/3_palisadesRF_eaton_sar_avgasc.tif\"\n",
    "path_4=\"MachineLearning/output/prediction/4_palisadesRF_eaton_sar_avgasc_glcm.tif\"\n",
    "path_5=\"MachineLearning/output/prediction/5_palisadesRF_eaton_sar_avgasc_desc.tif\"\n",
    "path_6=\"MachineLearning/output/prediction/6_palisadesRF_eaton_sar_avgasc_desc_glcm.tif\"\n",
    "\n",
    "paths=[path_1,path_2,path_3,path_4,path_5,path_6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance\n",
      "- Accuracy: 0.7414507772020725\n",
      "- F1 Score: 0.8064709648413507\n",
      "- Precision Score: 0.9314609394468442\n",
      "- Recall Score: 0.7414507772020725\n",
      "- Roc Auc Score: 0.7773528203479442\n",
      "Model performance\n",
      "- Accuracy: 0.7485751295336788\n",
      "- F1 Score: 0.8050050623356777\n",
      "- Precision Score: 0.9182342841290385\n",
      "- Recall Score: 0.7485751295336788\n",
      "- Roc Auc Score: 0.7751258835076634\n",
      "Model performance\n",
      "- Accuracy: 0.7576424870466322\n",
      "- F1 Score: 0.8114647051100977\n",
      "- Precision Score: 0.9237240564822375\n",
      "- Recall Score: 0.7576424870466322\n",
      "- Roc Auc Score: 0.8037229021129056\n",
      "Model performance\n",
      "- Accuracy: 0.7545336787564767\n",
      "- F1 Score: 0.811394642306356\n",
      "- Precision Score: 0.927976985225427\n",
      "- Recall Score: 0.7545336787564767\n",
      "- Roc Auc Score: 0.8042224723887181\n",
      "Model performance\n",
      "- Accuracy: 0.7432642487046632\n",
      "- F1 Score: 0.8172676982898824\n",
      "- Precision Score: 0.9573064131755439\n",
      "- Recall Score: 0.7432642487046632\n",
      "- Roc Auc Score: 0.8443044665932822\n",
      "Model performance\n",
      "- Accuracy: 0.7454663212435233\n",
      "- F1 Score: 0.8170081124267341\n",
      "- Precision Score: 0.9543150447582209\n",
      "- Recall Score: 0.7454663212435233\n",
      "- Roc Auc Score: 0.8415405421881403\n",
      "[{'acc_train': 0.7415, 'f1_train': 0.8065, 'precision_train': 0.9315, 'recall_train': 0.7415, 'roc_auc_train': np.float64(0.7774)}, {'acc_train': 0.7486, 'f1_train': 0.805, 'precision_train': 0.9182, 'recall_train': 0.7486, 'roc_auc_train': np.float64(0.7751)}, {'acc_train': 0.7576, 'f1_train': 0.8115, 'precision_train': 0.9237, 'recall_train': 0.7576, 'roc_auc_train': np.float64(0.8037)}, {'acc_train': 0.7545, 'f1_train': 0.8114, 'precision_train': 0.928, 'recall_train': 0.7545, 'roc_auc_train': np.float64(0.8042)}, {'acc_train': 0.7433, 'f1_train': 0.8173, 'precision_train': 0.9573, 'recall_train': 0.7433, 'roc_auc_train': np.float64(0.8443)}, {'acc_train': 0.7455, 'f1_train': 0.817, 'precision_train': 0.9543, 'recall_train': 0.7455, 'roc_auc_train': np.float64(0.8415)}]\n",
      "CSV file created successfully!\n"
     ]
    }
   ],
   "source": [
    "metrics_combined=[]\n",
    "for path in paths:\n",
    "    # Load sample points (make sure it has a 'class' column)\n",
    "    gdf = gpd.read_file(validation_sample_path)\n",
    "\n",
    "    # Open prediction raster\n",
    "    with rasterio.open(path) as src:\n",
    "        # Read the first band\n",
    "        prediction = src.read(1)\n",
    "        \n",
    "        # Get predicted value at each sample point location\n",
    "        coords = [(x,y) for x, y in zip(gdf.geometry.x, gdf.geometry.y)]\n",
    "        gdf['predicted'] = [val[0] for val in src.sample(coords)]\n",
    "\n",
    "    # Ground truth and predicted labels\n",
    "    y_true = gdf['class']\n",
    "    y_pred = gdf['predicted']\n",
    "    metrics_val=evaluate_model(y_pred,y_true)\n",
    "    metrics_val={\n",
    "        'acc_val': round(metrics_val['accuracy'],4),\n",
    "        'f1_val': round(metrics_val['f1_score'],4),\n",
    "        'precision_val': round(metrics_val['precision'],4),\n",
    "        'recall_val': round(metrics_val['recall'],4),\n",
    "        'roc_auc_val': round(metrics_val['roc_auc'],4)\n",
    "        }\n",
    "    metrics_combined.append(metrics_val)\n",
    "\n",
    "print(metrics_combined)\n",
    "# Convert to DataFrame\n",
    "df_metrics = pd.DataFrame(metrics_combined)\n",
    "\n",
    "# Save to CSV\n",
    "df_metrics.to_csv('MachineLearning/output/metrics_comparison_val.csv', index=False)\n",
    "\n",
    "print(\"CSV file created successfully!\")\n",
    "\n",
    "    # # Metrics\n",
    "    # print(\"Confusion Matrix:\")\n",
    "    # print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "    # print(\"\\nClassification Report:\")\n",
    "    # print(classification_report(y_true, y_pred, target_names=['Class 0', 'Class 1']))\n",
    "\n",
    "    # print(\"\\nOverall Accuracy:\")\n",
    "    # print(accuracy_score(y_true, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fire_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
