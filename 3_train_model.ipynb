{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.mdpi.com/2076-3417/12/19/10077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "from rasterio.sample import sample_gen\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report,ConfusionMatrixDisplay,\\\n",
    "                            precision_score,recall_score,f1_score,roc_auc_score, roc_curve\n",
    "\n",
    "# import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import joblib\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sample points and sar data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SAR GeoTIFF\n",
    "sar_image_path = \"output/sar_image/eaton_sar_indices.tif\"\n",
    "\n",
    "# Load the CSV data\n",
    "# training_data_path = 'sample_1_training_data.csv'\n",
    "# training_data_path=\"sample_1_training_data_texture.csv\"\n",
    "training_data_path=\"output/sample/training_data_eaton_indices.csv\"\n",
    "\n",
    "training_data=pd.read_csv(training_data_path)\n",
    "# feature_column_names=[\"gam_vh_post\",\"gam_vv_post\",\"gam_vh_pre\",\"gam_vv_pre\"]\n",
    "# feature_column_names=[\"gam_vh_post\",\"gam_vv_post\",\"gam_vh_pre\",\"gam_vv_pre\",\"RBD_VV\", \"RBD_VH\", \"RBR_VV\", \"RBR_VH\", \"ΔRVI\"]\n",
    "# feature_column_names=[\"RBD_VV\", \"RBD_VH\", \"RBR_VV\", \"RBR_VH\", \"ΔRVI\",'t1','t2','t3','t4','t5','t6','t7','t8','t9','t10','t11','t12','t13','t14','t15','t16','t17','t18','t19','t20']\n",
    "# \"dTRAD\",\"dNBR\",\n",
    "feature_column_names=[\"RBD_VV\", \"RBD_VH\", \"RBR_VV\", \"dod_RBR_VV\",\"RBR_VH\",\"dod_RBR_VH\",\"ΔRVI\",'Δvv_vh_ratio',\"ΔRDFI\",\"RCBI\",'t1','t2','t3','t4','t5','t6','t7','t8','t9','t10','t11','t12','t13','t14','t15','t16','t17','t18','t19','t20'] #,\"ΔRVI\",'Δvv_vh_ratio',\"ΔRDFI\",\"dTRAD\"\n",
    "\n",
    "# feature_column_names=[\"RBD_VV\", \"RBD_VH\", \"RBR_VV\", \"RBR_VH\", \"ΔRVI\",\"Δvv_vh_ratio\",\"ΔRDFI\"] #\n",
    "# feature_column_names=['t1','t2','t3','t4','t5','t6','t7','t8','t9','t10','t11','t12','t13','t14','t15','t16','t17','t18','t19','t20']\n",
    "# feature_column_names=[\"gamm_vh_pre\",\"gamm_vv_pre\",\"gamm_vh_post\",\"gamm_vv_post\",\"RBD_VV\", \"RBD_VH\", \"RBR_VV\", \"RBR_VH\", \"ΔRVI\"]\n",
    "# feature_column_names=[\"gamm_vh_pre\",\"gamm_vv_pre\",\"gamm_vh_post\",\"gamm_vv_post\",\"RBD_VV\", \"RBD_VH\", \"RBR_VV\", \"RBR_VH\", \"ΔRVI\",'t1','t2','t3','t4','t5','t6','t7','t8','t9','t10','t11','t12','t13','t14','t15','t16','t17','t18','t19','t20']\n",
    "\n",
    "class_column_name='class'\n",
    "extended_file_name=\"_reproject\"\n",
    "\n",
    "\n",
    "output_model_dir=\"output/model/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rasterio.open(sar_image_path)\n",
    "# Get the number of bands\n",
    "num_bands = dataset.count\n",
    "print(f\"Number of bands: {num_bands}\")\n",
    "\n",
    "# To get the names of the bands (if available)\n",
    "# for i in range(1, num_bands + 1):\n",
    "#     band_name = dataset.tags(i)  # Retrieve tags for the band\n",
    "#     print(f\"Band {i} name: {band_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (SAR bands) and labels (e.g., class column)\n",
    "X = training_data[feature_column_names]  # Features (SAR band values)\n",
    "Y = training_data[class_column_name]  # Labels (add 'Class' column in your CSV if available)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices_tex\n",
    "# RF_Model_1=RandomForestClassifier(n_estimators= 150, min_samples_split= 8, max_features= 9, max_depth= 10)\n",
    "\n",
    "#gamma_indices\n",
    "# RF_Model_1=RandomForestClassifier(n_estimators= 100, min_samples_split= 8, max_features= 20, max_depth= 8)\n",
    "\n",
    "#gamma\n",
    "# RF_Model_0=RandomForestClassifier(n_estimators= 150, min_samples_split= 15, max_features= 20, max_depth= 12)\n",
    "# RF_Model_1=RandomForestClassifier(n_estimators= 200, min_samples_split= 8, max_features= 20, max_depth= 8)\n",
    "# {'n_estimators': 150, 'min_samples_split': 20, 'max_features': 4, 'max_depth': 15}\n",
    "#indices\n",
    "# RF_Model_0=RandomForestClassifier(n_estimators= 150, min_samples_split= 4, max_features= 20, max_depth= 10)\n",
    "# RF_Model_1=RandomForestClassifier(n_estimators= 150, min_samples_split= 8, max_features= 7, max_depth= 8)\n",
    "\n",
    "\n",
    "#eaton indices\n",
    "# RF_Model_0=RandomForestClassifier(n_estimators= 200,random_state=42)\n",
    "# max_depth= 8\n",
    "# {'n_estimators': 100, 'min_samples_split': 40, 'max_features': 3, 'max_depth': 8}\n",
    "RF_Model_0=RandomForestClassifier(n_estimators= 100, min_samples_split= 40, max_features= 3,max_depth= 8,bootstrap=True)\n",
    "# RF_Model_1=RandomForestClassifier(n_estimators= 100, min_samples_split= 4, max_features= 8, max_depth= 5)\n",
    "# RF_Model_0 = RandomForestClassifier(\n",
    "#     n_estimators=100,               # Number of trees in the forest\n",
    "#     max_depth=None,                  # Trees can grow deep to capture complex patterns\n",
    "#     min_samples_split=2,             # Minimum samples required to split an internal node\n",
    "#     min_samples_leaf=1,              # Minimum samples required to be at a leaf node\n",
    "#     max_features='sqrt',             # Use square root of the total features for each split\n",
    "#     bootstrap=True,                  # Use bootstrap sampling (default)\n",
    "#     n_jobs=-1,                       # Use all available processors\n",
    "#     random_state=42                  # Ensures reproducibility\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "models={\n",
    "    \"RandomForest0\": RF_Model_0,\n",
    "    # \"RandomForest1\": RF_Model_1,\n",
    "    # \"RandomForest2\": RF_Model_2,\n",
    "    # \"RandomForest3\": RF_Model_3,\n",
    "    # \"RandomForest4\": RF_Model_4,\n",
    "    # \"RandomForest5\": RF_Model_5,\n",
    "\n",
    "    # \"Decision Tree\":DecisionTreeClassifier(),\n",
    "    # \"Logistic Regression\":LogisticRegression()\n",
    "    # \"XGBoost\": XGB_Model\n",
    "}\n",
    "\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model_name=list(models.keys())[i]\n",
    "    print(f\"***************{model_name}*********************\")\n",
    "    model=list(models.values())[i]\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # pixels_scaled = scaler.fit_transform(pixels)  # Apply scaling to the pixels\n",
    "    # X_train=scaler.fit_transform(X_train)\n",
    "    model.fit(X_train, y_train)\n",
    "    # print(\"score\",model.score(X_test,y_test))\n",
    "\n",
    "    #Make a prediction\n",
    "    y_train_pred=model.predict(X_train)\n",
    "    # y_test_pred=model.predict(scaler.transform(X_test))\n",
    "    y_test_pred=model.predict(X_test)\n",
    "\n",
    "\n",
    "    #Training set performance\n",
    "    model_train_accuracy=accuracy_score(y_train,y_train_pred)\n",
    "    model_train_f1=f1_score(y_train,y_train_pred,average='weighted')\n",
    "    model_train_precision=precision_score(y_train,y_train_pred)\n",
    "    model_train_recall=recall_score(y_train,y_train_pred)\n",
    "    model_train_roc_auc_score=roc_auc_score(y_train,y_train_pred)\n",
    "\n",
    "    #Test set performance\n",
    "    model_test_accuracy=accuracy_score(y_test,y_test_pred)\n",
    "    model_test_f1=f1_score(y_test,y_test_pred,average='weighted')\n",
    "    model_test_precision=precision_score(y_test,y_test_pred)\n",
    "    model_test_recall=recall_score(y_test,y_test_pred)\n",
    "    model_test_roc_auc_score=roc_auc_score(y_test,y_test_pred)\n",
    "\n",
    "    # print(model)\n",
    "    print('Model performance for Training set')\n",
    "    print(f\"- Accuracy: {model_train_accuracy}\")\n",
    "    print(f\"- F1 Score: {model_train_f1}\")\n",
    "    print(f\"- Precision Score: {model_train_precision}\")\n",
    "    print(f\"- Recall Score: {model_train_recall}\")\n",
    "    print(f\"- Roc Auc Score: {model_train_roc_auc_score}\")\n",
    "\n",
    "    print(\"--------------\")\n",
    "    print('Model performance for Test set')\n",
    "    print(f\"- Accuracy: {model_test_accuracy}\")\n",
    "    print(f\"- F1 Score: {model_test_f1}\")\n",
    "    print(f\"- Precision Score: {model_test_precision}\")\n",
    "    print(f\"- Recall Score: {model_test_recall}\")\n",
    "    print(f\"- Roc Auc Score: {model_test_roc_auc_score}\")\n",
    "    print(\"----------------------------------------\")\n",
    "\n",
    "    \n",
    "    # Assuming you have a trained model called `model`\n",
    "    joblib.dump(model, f'{output_model_dir}{model_name}.pkl')\n",
    "\n",
    "    print(\"Model saved successfully!\")\n",
    "\n",
    "    # predict(model, sar_image_path,model_name,scaler)\n",
    "    # predict(model, sar_image_path,model_name)\n",
    "\n",
    "    # predict(model, \"output/sar_image/palisades_sar_indices.tif\",model_name)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "# rf_classifier = RandomForestClassifier(n_estimators= 100)\n",
    "\n",
    "# # Train the model\n",
    "# rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate the model\n",
    "# accuracy = rf_classifier.score(X_test, y_test)\n",
    "# print(f\"Random Forest Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# Model performance for Training set\n",
    "# - Accuracy: 0.9043069948186528\n",
    "# - F1 Score: 0.9032436217125988\n",
    "# - Precision Score: 0.8647854203409759\n",
    "# - Recall Score: 0.8029475982532751\n",
    "# - Roc Auc Score: 0.8750005026257168\n",
    "# --------------\n",
    "# Model performance for Test set\n",
    "# - Accuracy: 0.8853626943005182\n",
    "# - F1 Score: 0.8834883526398328\n",
    "# - Precision Score: 0.8531468531468531\n",
    "# - Recall Score: 0.7625\n",
    "# - Roc Auc Score: 0.8516447368421053"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series containing feature importances from the model and feature names from the training data\n",
    "\n",
    "feature_importances = pd.Series(RF_Model_0.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "# Plot a simple bar chart\n",
    "feature_importances.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "corr_mat_export_path=\"output/correlation/cor_mat.csv\"\n",
    "# Compute Pearson correlation matrix\n",
    "training_data_1 = training_data.drop(columns=['id','class','geometry'])\n",
    "correlation_matrix = training_data_1.corr(method='pearson').round(2)\n",
    "print(correlation_matrix)\n",
    "correlation_matrix = correlation_matrix.applymap(lambda x: x if x >= 0.7 else 0)\n",
    "correlation_matrix.to_csv(corr_mat_export_path, index=True)\n",
    "\n",
    "# corr_matrix = df.corr()\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".1f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction for entire image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image_path,model_name ):\n",
    "    dataset = rasterio.open(image_path)\n",
    "    print(dataset.count)\n",
    "    # # Load the SAR GeoTIFF\n",
    "    # image_path = \"../SAR_Data_processing/11_export/palisades_indices_subset.tif\"\n",
    "    # dataset = rasterio.open(image_path)\n",
    "\n",
    "    # Read the image bands into an array (assuming it's a multi-band raster)\n",
    "    sar_bands = np.stack([dataset.read(i+1) for i in range(dataset.count)], axis=-1)\n",
    "\n",
    "    # Reshape the SAR data to a 2D array (num_pixels, num_bands)\n",
    "    height, width, num_bands = sar_bands.shape\n",
    "    pixels = sar_bands.reshape(-1, num_bands)  # Each row is a pixel\n",
    "    print(num_bands,\"num_bands\")\n",
    "\n",
    "    # Preprocess (scale) the pixel values if needed (based on training data preprocessing)\n",
    "    # scaler = StandardScaler()\n",
    "    # pixels_scaled = scaler.fit_transform(pixels)  # Apply scaling to the pixels\n",
    "\n",
    "    # Predict for each pixel\n",
    "    predictions = model.predict(pixels)\n",
    "\n",
    "    from scipy.ndimage import uniform_filter\n",
    "    # Assuming predictions are a 2D array (for an image or spatial data)\n",
    "    predictions = uniform_filter(predictions, size=7)  # size is the window size\n",
    "\n",
    "    # predictions = model.predict(scaler.transform(pixels))\n",
    "\n",
    "\n",
    "    # Reshape predictions to match the image dimensions\n",
    "    predicted_image = predictions.reshape(height, width)\n",
    "\n",
    "    # Save the predicted classes to a new file\n",
    "    output_path = f\"output/prediction/eaton_{model_name}_{extended_file_name}.tif\"\n",
    "    meta = dataset.meta\n",
    "    meta.update(dtype=rasterio.uint8, count=1)  # Assuming class labels are integers, uint8 works for this\n",
    "\n",
    "    with rasterio.open(output_path, 'w', **meta) as dest:\n",
    "        dest.write(predicted_image.astype(rasterio.uint8), 1)  # Write to the first band\n",
    "\n",
    "    print(f\"Predictions saved to {output_path}\")\n",
    "\n",
    "    pred_dataset = rasterio.open(output_path)\n",
    "\n",
    "    # Read the first band of the image (you can adjust for multi-band images)\n",
    "    pred_band_1 = pred_dataset.read(1)\n",
    "\n",
    "    # Plot the image\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(pred_band_1, cmap='gray')  # You can adjust the colormap if needed\n",
    "    plt.colorbar()\n",
    "    plt.title(\"SAR Burnt Area Prediction Map\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_models=os.listdir(output_model_dir)\n",
    "for model_name in ml_models:\n",
    "    output_model_path = os.path.join(output_model_dir, model_name)\n",
    "    # Load the saved model\n",
    "    loaded_model = joblib.load(output_model_path)\n",
    "\n",
    "    # Use the loaded model to make predictions\n",
    "    # predictions = loaded_model.predict(X_test)\n",
    "    predict(loaded_model, sar_image_path,model_name.replace(\".pkl\",\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot AUC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot ROC AUC Curve\n",
    "plt.figure()\n",
    "auc_models = [{\n",
    "    'label': 'Random Forest Classifier',\n",
    "    'model': RF_Model,\n",
    "    'auc':0.73\n",
    "}]\n",
    "\n",
    "for algo in auc_models:\n",
    "    model=algo['model']\n",
    "    model.fit(X_train, y_train)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    plt.plot(fpr,tpr,label=\"Random Forest Classifier ROC (area= 0.71)\")\n",
    "\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('1-Specificity (False Positive Rate)')\n",
    "    plt.ylabel('Sensitivity (True Positive Rate)')\n",
    "    plt.title('Receiver operating characteristics')\n",
    "\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.savefig(\"auc.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # Open the TIFF file using rasterio\n",
    "    # output_path = \"palisades_predictions.tif\"  # Replace with your TIFF file path\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction for entire image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import rasterio\n",
    "# # import matplotlib.pyplot as plt\n",
    "\n",
    "# # Open the TIFF file using rasterio\n",
    "# output_path = \"palisades_predictions.tif\"  # Replace with your TIFF file path\n",
    "# dataset = rasterio.open(output_path)\n",
    "\n",
    "# # Read the first band of the image (you can adjust for multi-band images)\n",
    "# band1 = dataset.read(1)\n",
    "\n",
    "# # Plot the image\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(band1, cmap='gray')  # You can adjust the colormap if needed\n",
    "# plt.colorbar()\n",
    "# plt.title(\"SAR Image\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your trained RF model (update with your actual model path)\n",
    "# rf_model = joblib.load('path_to_your_trained_rf_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Example thermal values\n",
    "# thermal_values = np.array([-500, 0, 1000, 1500])\n",
    "\n",
    "# # Standardization (Z-score)\n",
    "# mean = np.mean(thermal_values)\n",
    "# std_dev = np.std(thermal_values)\n",
    "# standardized_values = (thermal_values - mean) / std_dev\n",
    "\n",
    "# print(\"Standardized values:\", standardized_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fire_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
